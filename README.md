# Сравнительная оценка игровых моделей для оценки и визуализации взаимодействий между нейронами в нейронной сети прямого распространения

Jupyter-блокнот `FFNNComparison.ipynb` содержит сравнительное исследование трех различных методов регуляризации нейронных сетей:

1.  **Базовая модель (без регуляризации)**
2.  **Классический Dropout**
3.  **Gradient Dropout** (предложенный в этом блокноте)

Исследование проводится на задаче регрессии, где нейронная сеть учится аппроксимировать функцию `sin(x + y)`. Цель — проанализировать, как каждый из этих методов влияет на процесс обучения, сходимость и качество полученного решения, а также на устойчивость к локальным минимумам.

Блокнот включает:

*   Определение целевой функции и генерацию синтетических данных.
*   Реализацию класса `GradientDropout` как кастомной функции PyTorch.
*   Создание и инициализацию трех моделей нейронных сетей с различными типами регуляризации.
*   Проведение экспериментов с двумя типами инициализации весов:
    *   Случайная инициализация (равномерное распределение)
    *   Инициализация Хе (Kaiming initialization)
*   Визуализацию результатов обучения, включая 3D-графики предсказанной функции и графики динамики потерь (MSE) во времени.
*   Анализ и интерпретацию полученных результатов с точки зрения теории игр и эффективности обучения.

**Цель:** Продемонстрировать, что Gradient Dropout может обеспечить баланс между быстрой оптимизацией и робастной регуляризацией, способствуя более качественному и устойчивому равновесию в нейронной сети.